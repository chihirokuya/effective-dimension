{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import patsy\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from package.fim.fim import compute_fims_nn\n",
    "from package.plot_utils.common import SINGLE_PLOT_FIGSIZE, DPI\n",
    "from package.neural_network.fit import fit_nn, FitOption\n",
    "from package.data.mnist import load_data\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n",
    "input_dim = 28*28\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/effective-dimension')\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "from package.effective_dimension.effective_dimension import EDType, EffectiveDimensionApprox\n",
    "from package.fim.fim import compute_fims_nn\n",
    "from package.neural_network.neural_network import ClassNetwork\n",
    "from package.neural_network.util import get_dimension\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from package.directories import data_dir, weights_dir, eigenvalues_dir\n",
    "\n",
    "plt.figure(figsize=(8, 5), dpi=300)\n",
    "\n",
    "\n",
    "def load_data(batch_size: int=64):\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    trainset = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, testloader\n",
    "\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n",
    "input_dim = 28*28\n",
    "layer_sizes = [20, 20, 20, 20]\n",
    "output_dim = 10\n",
    "\n",
    "os.mkdir(weights_dir)\n",
    "os.mkdir(eigenvalues_dir)\n",
    "\n",
    "if not os.path.isdir(os.path.join(weights_dir, 'temp')):\n",
    "    os.mkdir(os.path.join(weights_dir, 'temp'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(eigenvalues_dir, 'temp')):\n",
    "    os.mkdir(os.path.join(eigenvalues_dir, 'temp'))\n",
    "\n",
    "for i, rate in enumerate([0, 0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "\n",
    "    network = ClassNetwork(input_dim, layer_sizes, output_dim, dropout_rate=rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    network = network.to(torch.device(device))\n",
    "\n",
    "    save_epochs = [1, 5, 10, 15, 20]\n",
    "\n",
    "    if not os.path.isdir(os.path.join(weights_dir, 'temp', f'{i}')):\n",
    "        os.mkdir(os.path.join(weights_dir, 'temp', f'{i}'))\n",
    "\n",
    "    run_dir = os.path.join(weights_dir, f'temp', f'{i}')\n",
    "\n",
    "    shutil.rmtree(run_dir)\n",
    "    os.mkdir(run_dir)\n",
    "\n",
    "    epochs = 20\n",
    "    network.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / total_samples\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if epoch+1 in save_epochs:\n",
    "            network.eval()\n",
    "            model_path = os.path.join(\n",
    "                run_dir, f'epoch_{epoch + 1}.pth')\n",
    "            if os.path.isfile(model_path):\n",
    "                os.remove(model_path)\n",
    "            torch.save(network.state_dict(), model_path)\n",
    "            network.train()\n",
    "\n",
    "\n",
    "    del network\n",
    "\n",
    "    eff_dims = []\n",
    "    from tqdm import tqdm\n",
    "    with tqdm(save_epochs, desc=f\"Computing EDs\", unit=\"epoch\") as pbar:\n",
    "        for epoch in pbar:\n",
    "            network = ClassNetwork(input_dim, layer_sizes, output_dim, dropout_rate=rate)\n",
    "            model_path = os.path.join(\n",
    "                    run_dir, f'epoch_{epoch}.pth')\n",
    "\n",
    "            network.load_state_dict(torch.load(model_path))\n",
    "            network.eval()\n",
    "\n",
    "            if not os.path.isdir(os.path.join(eigenvalues_dir, 'temp', f'{i}')):\n",
    "                os.mkdir(os.path.join(eigenvalues_dir, 'temp', f'{i}'))\n",
    "\n",
    "            compute_fims_nn(\n",
    "                input_dim,\n",
    "                layer_sizes,\n",
    "                output_dim,\n",
    "\n",
    "                num_thetas=1,\n",
    "                save_dir=os.path.join(eigenvalues_dir, 'temp', f'{i}'),\n",
    "                filename=f'temp_{epoch+1}',\n",
    "\n",
    "                data_loader=train_loader,\n",
    "\n",
    "                network=network,\n",
    "                theta_min=-5e-3,\n",
    "                theta_max=5e-3,\n",
    "\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            network = network.to(torch.device(device))\n",
    "\n",
    "            if epoch == save_epochs[-1]:\n",
    "                epoch_loss = 0.0\n",
    "                total_samples = 0\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = network(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_size = inputs.size(0)\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                avg_loss_test = epoch_loss / total_samples\n",
    "\n",
    "                epoch_loss = 0.0\n",
    "                total_samples = 0\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = network(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_size = inputs.size(0)\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                avg_loss_train = epoch_loss / total_samples\n",
    "\n",
    "                print(f'{i}, {dim}, Train {avg_loss_train}, Test {avg_loss_test}, Gen err: {abs(avg_loss_test - avg_loss_train)}, eff dim: {eff_dims[-1]}')\n",
    "\n",
    "            del network\n",
    "\n",
    "            dim = get_dimension(input_dim, layer_sizes, output_dim)\n",
    "\n",
    "            file_paths = os.path.join(eigenvalues_dir, f'temp', f'{i}', f'temp_{epoch+1}_{dim}.h5')\n",
    "            ef = EffectiveDimensionApprox(file_paths, file_paths)\n",
    "            eff_dims.append(\n",
    "                ef.compute(60000, EDType.LOCAL, gamma=1, eps=1e-7, chunk_size=5, verbose=False)[0] / dim\n",
    "            )\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(save_epochs, eff_dims, label=f'Rate={rate}')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Normalized Effective Dimension')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Normalized Effective Dimension of Neural Networks\\nVarying Dropout Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/effective-dimension')\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "from package.effective_dimension.effective_dimension import EDType, EffectiveDimensionApprox\n",
    "from package.fim.fim import compute_fims_nn\n",
    "from package.neural_network.neural_network import ClassNetwork\n",
    "from package.neural_network.util import get_dimension\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from package.directories import data_dir, weights_dir, eigenvalues_dir\n",
    "\n",
    "plt.figure(figsize=(8, 5), dpi=300)\n",
    "\n",
    "\n",
    "def load_data(batch_size: int=64):\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    trainset = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, testloader\n",
    "\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n",
    "input_dim = 28*28\n",
    "layer_sizes = [100, 100]\n",
    "output_dim = 10\n",
    "\n",
    "os.mkdir(weights_dir)\n",
    "os.mkdir(eigenvalues_dir)\n",
    "\n",
    "if not os.path.isdir(os.path.join(weights_dir, 'temp')):\n",
    "    os.mkdir(os.path.join(weights_dir, 'temp'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(eigenvalues_dir, 'temp')):\n",
    "    os.mkdir(os.path.join(eigenvalues_dir, 'temp'))\n",
    "\n",
    "for i, rate in enumerate([0, 0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "\n",
    "    network = ClassNetwork(input_dim, layer_sizes, output_dim, dropout_rate=rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    network = network.to(torch.device(device))\n",
    "\n",
    "    save_epochs = [1, 5, 10, 15, 20]\n",
    "\n",
    "    if not os.path.isdir(os.path.join(weights_dir, 'temp', f'{i}')):\n",
    "        os.mkdir(os.path.join(weights_dir, 'temp', f'{i}'))\n",
    "\n",
    "    run_dir = os.path.join(weights_dir, f'temp', f'{i}')\n",
    "\n",
    "    shutil.rmtree(run_dir)\n",
    "    os.mkdir(run_dir)\n",
    "\n",
    "    epochs = 20\n",
    "    network.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / total_samples\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if epoch+1 in save_epochs:\n",
    "            network.eval()\n",
    "            model_path = os.path.join(\n",
    "                run_dir, f'epoch_{epoch + 1}.pth')\n",
    "            if os.path.isfile(model_path):\n",
    "                os.remove(model_path)\n",
    "            torch.save(network.state_dict(), model_path)\n",
    "            network.train()\n",
    "\n",
    "\n",
    "    del network\n",
    "\n",
    "    eff_dims = []\n",
    "    from tqdm import tqdm\n",
    "    with tqdm(save_epochs, desc=f\"Computing EDs\", unit=\"epoch\") as pbar:\n",
    "        for epoch in pbar:\n",
    "            network = ClassNetwork(input_dim, layer_sizes, output_dim, dropout_rate=rate)\n",
    "            model_path = os.path.join(\n",
    "                    run_dir, f'epoch_{epoch}.pth')\n",
    "\n",
    "            network.load_state_dict(torch.load(model_path))\n",
    "            network.eval()\n",
    "\n",
    "            if not os.path.isdir(os.path.join(eigenvalues_dir, 'temp', f'{i}')):\n",
    "                os.mkdir(os.path.join(eigenvalues_dir, 'temp', f'{i}'))\n",
    "\n",
    "            compute_fims_nn(\n",
    "                input_dim,\n",
    "                layer_sizes,\n",
    "                output_dim,\n",
    "\n",
    "                num_thetas=1,\n",
    "                save_dir=os.path.join(eigenvalues_dir, 'temp', f'{i}'),\n",
    "                filename=f'temp_{epoch+1}',\n",
    "\n",
    "                data_loader=train_loader,\n",
    "\n",
    "                network=network,\n",
    "                theta_min=-5e-3,\n",
    "                theta_max=5e-3,\n",
    "\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            network = network.to(torch.device(device))\n",
    "\n",
    "            if epoch == save_epochs[-1]:\n",
    "                epoch_loss = 0.0\n",
    "                total_samples = 0\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = network(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_size = inputs.size(0)\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                avg_loss_test = epoch_loss / total_samples\n",
    "\n",
    "                epoch_loss = 0.0\n",
    "                total_samples = 0\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = network(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_size = inputs.size(0)\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                avg_loss_train = epoch_loss / total_samples\n",
    "\n",
    "                print(f'{i}, {dim}, Train {avg_loss_train}, Test {avg_loss_test}, Gen err: {abs(avg_loss_test - avg_loss_train)}, eff dim: {eff_dims[-1]}')\n",
    "\n",
    "            del network\n",
    "\n",
    "            dim = get_dimension(input_dim, layer_sizes, output_dim)\n",
    "\n",
    "            file_paths = os.path.join(eigenvalues_dir, f'temp', f'{i}', f'temp_{epoch+1}_{dim}.h5')\n",
    "            ef = EffectiveDimensionApprox(file_paths, file_paths)\n",
    "            eff_dims.append(\n",
    "                ef.compute(60000, EDType.LOCAL, gamma=1, eps=1e-7, chunk_size=5, verbose=False)[0] / dim\n",
    "            )\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(save_epochs, eff_dims, label=f'Rate={rate}')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Normalized Effective Dimension')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Normalized Effective Dimension of Neural Networks\\nVarying Dropout Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/effective-dimension')\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "from package.effective_dimension.effective_dimension import EDType, EffectiveDimensionApprox\n",
    "from package.fim.fim import compute_fims_nn\n",
    "from package.neural_network.neural_network import ClassNetwork\n",
    "from package.neural_network.util import get_dimension\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from package.directories import data_dir, weights_dir, eigenvalues_dir\n",
    "\n",
    "plt.figure(figsize=(8, 5), dpi=300)\n",
    "\n",
    "\n",
    "def load_data(batch_size: int=64):\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    trainset = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, testloader\n",
    "\n",
    "\n",
    "train_loader, test_loader = load_data()\n",
    "\n",
    "input_dim = 28*28\n",
    "layer_sizes = [10]\n",
    "output_dim = 10\n",
    "\n",
    "os.mkdir(weights_dir)\n",
    "os.mkdir(eigenvalues_dir)\n",
    "\n",
    "if not os.path.isdir(os.path.join(weights_dir, 'temp')):\n",
    "    os.mkdir(os.path.join(weights_dir, 'temp'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(eigenvalues_dir, 'temp')):\n",
    "    os.mkdir(os.path.join(eigenvalues_dir, 'temp'))\n",
    "\n",
    "for i, rate in enumerate([0, 0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "\n",
    "    network = ClassNetwork(input_dim, layer_sizes, output_dim, dropout_rate=rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    network = network.to(torch.device(device))\n",
    "\n",
    "    save_epochs = [1, 5, 10, 15, 20]\n",
    "\n",
    "    if not os.path.isdir(os.path.join(weights_dir, 'temp', f'{i}')):\n",
    "        os.mkdir(os.path.join(weights_dir, 'temp', f'{i}'))\n",
    "\n",
    "    run_dir = os.path.join(weights_dir, f'temp', f'{i}')\n",
    "\n",
    "    shutil.rmtree(run_dir)\n",
    "    os.mkdir(run_dir)\n",
    "\n",
    "    epochs = 20\n",
    "    network.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / total_samples\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if epoch+1 in save_epochs:\n",
    "            network.eval()\n",
    "            model_path = os.path.join(\n",
    "                run_dir, f'epoch_{epoch + 1}.pth')\n",
    "            if os.path.isfile(model_path):\n",
    "                os.remove(model_path)\n",
    "            torch.save(network.state_dict(), model_path)\n",
    "            network.train()\n",
    "\n",
    "\n",
    "    del network\n",
    "\n",
    "    eff_dims = []\n",
    "    from tqdm import tqdm\n",
    "    with tqdm(save_epochs, desc=f\"Computing EDs\", unit=\"epoch\") as pbar:\n",
    "        for epoch in pbar:\n",
    "            network = ClassNetwork(input_dim, layer_sizes, output_dim, dropout_rate=rate)\n",
    "            model_path = os.path.join(\n",
    "                    run_dir, f'epoch_{epoch}.pth')\n",
    "\n",
    "            network.load_state_dict(torch.load(model_path))\n",
    "            network.eval()\n",
    "\n",
    "            if not os.path.isdir(os.path.join(eigenvalues_dir, 'temp', f'{i}')):\n",
    "                os.mkdir(os.path.join(eigenvalues_dir, 'temp', f'{i}'))\n",
    "\n",
    "            compute_fims_nn(\n",
    "                input_dim,\n",
    "                layer_sizes,\n",
    "                output_dim,\n",
    "\n",
    "                num_thetas=1,\n",
    "                save_dir=os.path.join(eigenvalues_dir, 'temp', f'{i}'),\n",
    "                filename=f'temp_{epoch+1}',\n",
    "\n",
    "                data_loader=train_loader,\n",
    "\n",
    "                network=network,\n",
    "                theta_min=-5e-3,\n",
    "                theta_max=5e-3,\n",
    "\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            network = network.to(torch.device(device))\n",
    "\n",
    "            if epoch == save_epochs[-1]:\n",
    "                epoch_loss = 0.0\n",
    "                total_samples = 0\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = network(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_size = inputs.size(0)\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                avg_loss_test = epoch_loss / total_samples\n",
    "\n",
    "                epoch_loss = 0.0\n",
    "                total_samples = 0\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = network(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_size = inputs.size(0)\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                avg_loss_train = epoch_loss / total_samples\n",
    "\n",
    "                print(f'{i}, {dim}, Train {avg_loss_train}, Test {avg_loss_test}, Gen err: {abs(avg_loss_test - avg_loss_train)}, eff dim: {eff_dims[-1]}')\n",
    "\n",
    "            del network\n",
    "\n",
    "            dim = get_dimension(input_dim, layer_sizes, output_dim)\n",
    "\n",
    "            file_paths = os.path.join(eigenvalues_dir, f'temp', f'{i}', f'temp_{epoch+1}_{dim}.h5')\n",
    "            ef = EffectiveDimensionApprox(file_paths, file_paths)\n",
    "            eff_dims.append(\n",
    "                ef.compute(60000, EDType.LOCAL, gamma=1, eps=1e-7, chunk_size=5, verbose=False)[0] / dim\n",
    "            )\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(save_epochs, eff_dims, label=f'Rate={rate}')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Normalized Effective Dimension')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Normalized Effective Dimension of Neural Networks\\nVarying Dropout Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
